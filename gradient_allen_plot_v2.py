"""
gradient_allen_plot_v2.py

Interactive 3-slice viewer for summary outputs generated by gradient_allen_v2.py.

- Input: data/gradient_allen/v2_allpoints_gradient_*x_cell*.npy
- Viewer: XY / YZ / ZX slices with x/y/z sliders + time slider
- Metric selection: vm0_mV, vm_max_mV, vm_min_mV, vm_by_t, spike_count, spike_on
- Time slider: for vm_by_t/spike_on, shows Vm at selected time in 0~1 ms
"""

from __future__ import annotations

import argparse
import math
from pathlib import Path
from typing import Any, Dict, List, Tuple

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.widgets import Slider, RadioButtons

def _gain_tag(v: float) -> str:
    fv = float(v)
    if fv <= 0.0:
        return str(fv).rstrip("0").rstrip(".").replace(".", "p")
    if abs(fv - 1.0) < 1e-12:
        return "1"
    exp = math.log10(fv)
    exp_i = int(round(exp))
    if abs(exp - exp_i) < 1e-12 and exp_i >= 1:
        return f"10e{exp_i - 1}"
    return str(fv).rstrip("0").rstrip(".").replace(".", "p")


def _find_inputs_v2(script_dir: Path, cell_id: str | None = None) -> List[Path]:
    """Find v2 summary files sorted by modified time (newest first)."""
    outdir = script_dir / "data" / "gradient_allen"
    if not outdir.is_dir():
        return []

    if cell_id:
        candidates = list(outdir.glob(f"v2_allpoints_gradient_*x_cell{cell_id}.npy"))
    else:
        candidates = list(outdir.glob("v2_allpoints_gradient_*x_cell*.npy"))

    candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return candidates


def _dataset_label(path: Path, payload: dict) -> str:
    cell = str(payload.get("cell_id", "unknown"))
    gain = payload.get("gradient_gain", "N/A")
    if isinstance(gain, (float, int, np.floating, np.integer)):
        gain_tag = f"{float(gain):g}x"
    else:
        gain_tag = str(gain)
    return f"cell {cell} | gain {gain_tag}"


def _load_payload(path: Path) -> dict:
    data = np.load(str(path), allow_pickle=True)
    if isinstance(data, np.ndarray) and data.ndim == 0:
        data = data.item()
    if not isinstance(data, dict):
        raise TypeError(f"Unexpected root type in npy: {type(data)}")

    required = [
        "positions_um",
        "positions_outside_indices",
        "vm0_mV",
        "vm_max_mV",
        "vm_min_mV",
        "vm_trace_t_ms",
        "vm_trace_0to1ms_mV",
        "spike_count",
        "spike_times_ms",
        "t_ms",
    ]
    for key in required:
        if key not in data:
            raise KeyError(
                f"Key '{key}' not found. Need gradient_allen_v2.py output (v2_* file). "
                f"Keys: {list(data.keys())}"
            )
    return data


def _grid_axes_from_positions(positions_um: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    if positions_um.ndim != 2 or positions_um.shape[1] != 3:
        raise ValueError(f"positions_um shape must be (N, 3), got {positions_um.shape}")

    x = np.round(positions_um[:, 0], 6)
    y = np.round(positions_um[:, 1], 6)
    z = np.round(positions_um[:, 2], 6)

    xu = np.unique(x)
    yu = np.unique(y)
    zu = np.unique(z)
    xu.sort()
    yu.sort()
    zu.sort()
    return xu, yu, zu


def _build_metric_volumes(payload: dict) -> Tuple[Dict[str, np.ndarray], np.ndarray, np.ndarray, np.ndarray]:
    positions = np.asarray(payload["positions_um"], dtype=np.float64)

    xu, yu, zu = _grid_axes_from_positions(positions)
    nx, ny, nz = xu.size, yu.size, zu.size

    metrics_1d = {
        "vm0_mV": np.asarray(payload["vm0_mV"], dtype=np.float64),
        "vm_max_mV": np.asarray(payload["vm_max_mV"], dtype=np.float64),
        "vm_min_mV": np.asarray(payload["vm_min_mV"], dtype=np.float64),
        "spike_count": np.asarray(payload["spike_count"], dtype=np.float64),
    }

    n_points = positions.shape[0]
    for name, arr in metrics_1d.items():
        if arr.shape[0] != n_points:
            raise ValueError(f"{name} length mismatch. {name}: {arr.shape[0]}, positions: {n_points}")

    x = np.round(positions[:, 0], 6)
    y = np.round(positions[:, 1], 6)
    z = np.round(positions[:, 2], 6)

    xi = np.searchsorted(xu, x)
    yi = np.searchsorted(yu, y)
    zi = np.searchsorted(zu, z)

    valid = (
        (xi >= 0) & (xi < nx)
        & (yi >= 0) & (yi < ny)
        & (zi >= 0) & (zi < nz)
        & (xu[xi] == x)
        & (yu[yi] == y)
        & (zu[zi] == z)
    )
    if not np.all(valid):
        bad = int(np.sum(~valid))
        raise ValueError(f"Coordinate-to-grid mapping failed for {bad} points.")

    flat = xi * (ny * nz) + yi * nz + zi
    if np.unique(flat).size != flat.size:
        raise ValueError("Duplicate coordinates found in positions_um; cannot build unique voxel map.")

    volumes: Dict[str, np.ndarray] = {}
    for name, values in metrics_1d.items():
        vol = np.full((nx, ny, nz), np.nan, dtype=np.float64)
        vol[xi, yi, zi] = values
        volumes[name] = vol

    return volumes, xu, yu, zu


def _build_vm_by_t_volume(
    payload: dict,
    t_ms: float,
    xu: np.ndarray,
    yu: np.ndarray,
    zu: np.ndarray,
) -> np.ndarray:
    """Build a volume where each voxel = Vm at selected time t_ms."""
    positions = np.asarray(payload["positions_um"], dtype=np.float64)
    vm_trace_t = np.asarray(payload["vm_trace_t_ms"], dtype=np.float64)
    vm_trace = np.asarray(payload["vm_trace_0to1ms_mV"], dtype=np.float64)
    nx, ny, nz = xu.size, yu.size, zu.size

    if vm_trace.ndim != 2 or vm_trace.shape[0] != positions.shape[0]:
        raise ValueError("vm_trace_0to1ms_mV shape mismatch.")
    if vm_trace.shape[1] != vm_trace_t.size:
        raise ValueError("vm_trace_0to1ms_mV and vm_trace_t_ms mismatch.")

    ti = _nearest_idx(vm_trace_t, float(t_ms))
    vm_vals = vm_trace[:, ti]

    x = np.round(positions[:, 0], 6)
    y = np.round(positions[:, 1], 6)
    z = np.round(positions[:, 2], 6)
    xi = np.searchsorted(xu, x)
    yi = np.searchsorted(yu, y)
    zi = np.searchsorted(zu, z)

    vol = np.full((nx, ny, nz), np.nan, dtype=np.float64)
    valid = (
        (xi >= 0) & (xi < nx)
        & (yi >= 0) & (yi < ny)
        & (zi >= 0) & (zi < nz)
        & (xu[xi] == x)
        & (yu[yi] == y)
        & (zu[zi] == z)
    )
    vol[xi[valid], yi[valid], zi[valid]] = vm_vals[valid]
    return vol


def _nearest_idx(axis_vals: np.ndarray, value: float) -> int:
    return int(np.argmin(np.abs(axis_vals - value)))


def _safe_step(axis_vals: np.ndarray) -> float:
    if axis_vals.size < 2:
        return 1.0
    diffs = np.diff(axis_vals)
    diffs = diffs[np.isfinite(diffs) & (diffs > 0)]
    if diffs.size == 0:
        return 1.0
    return float(np.min(diffs))


def _finite_minmax(vol: np.ndarray) -> Tuple[float, float]:
    finite = vol[np.isfinite(vol)]
    if finite.size == 0:
        return 0.0, 1.0
    return float(np.min(finite)), float(np.max(finite))


def _metric_scale(vol: np.ndarray, metric: str) -> Tuple[float, float, str]:
    mn, mx = _finite_minmax(vol)
    if metric in ("vm0_mV",):
        abs_max = max(abs(mn), abs(mx))
        if abs_max <= 0:
            abs_max = 1e-6
        return -abs_max, abs_max, "RdBu_r"
    if metric in ("vm_max_mV", "vm_min_mV"):
        if mx <= mn:
            mx = mn + 1e-6
        return mn, mx, "viridis"
    if metric in ("spike_count",):
        if mx <= mn:
            mx = mn + 1.0
        return mn, mx, "copper"
    if mx <= mn:
        mx = mn + 1.0
    return mn, mx, "magma"


def show_interactive(dataset_items: List[Tuple[str, Path, dict]]) -> None:
    if not dataset_items:
        raise ValueError("No datasets to plot.")

    metric_names = ["vm0_mV", "vm_max_mV", "vm_min_mV", "vm_by_t", "spike_count", "spike_on"]
    metric_label = {
        "vm0_mV": "Vm at t=0 (mV)",
        "vm_max_mV": "Vm max (mV)",
        "vm_min_mV": "Vm min (mV)",
        "vm_by_t": "Vm at selected t (mV)",
        "spike_count": "Spike count (total)",
        "spike_on": "Spike ON (Vm > 0)",
    }

    datasets: Dict[str, Dict[str, Any]] = {}
    xu_ref = yu_ref = zu_ref = None
    t_min_all = np.inf
    t_max_all = -np.inf
    t_step_all = np.inf

    for label, path, payload in dataset_items:
        volumes, xu, yu, zu = _build_metric_volumes(payload)
        vm_trace_t = np.asarray(payload["vm_trace_t_ms"], dtype=np.float64)
        t_min = float(vm_trace_t[0])
        t_max = float(vm_trace_t[-1])
        t_step = float(np.min(np.diff(vm_trace_t))) if vm_trace_t.size > 1 else 0.05

        if xu_ref is None:
            xu_ref, yu_ref, zu_ref = xu, yu, zu
        else:
            if not (np.array_equal(xu_ref, xu) and np.array_equal(yu_ref, yu) and np.array_equal(zu_ref, zu)):
                raise ValueError("All datasets must share the same spatial grid to switch by radio.")

        scale_cache: Dict[str, Tuple[float, float, str]] = {
            name: _metric_scale(volumes[name], name)
            for name in metric_names
            if name not in ("spike_on", "vm_by_t")
        }
        scale_cache["vm_by_t"] = (-100.0, 100.0, "RdBu_r")
        scale_cache["spike_on"] = (-0.5, 1.5, "bwr")

        datasets[label] = {
            "path": path,
            "payload": payload,
            "volumes": volumes,
            "xu": xu,
            "yu": yu,
            "zu": zu,
            "scale_cache": scale_cache,
            "t_min": t_min,
            "t_max": t_max,
            "t_step": t_step,
            "cell_id": str(payload.get("cell_id", "N/A")),
            "gain": payload.get("gradient_gain", "N/A"),
        }

        t_min_all = min(t_min_all, t_min)
        t_max_all = max(t_max_all, t_max)
        t_step_all = min(t_step_all, t_step)

    xu = xu_ref
    yu = yu_ref
    zu = zu_ref
    nx, ny, nz = xu.size, yu.size, zu.size

    labels = list(datasets.keys())
    init_dataset = labels[0]
    init_metric = "vm_by_t"
    t_init = max(t_min_all, min(0.1, t_max_all))
    init_vol = _build_vm_by_t_volume(datasets[init_dataset]["payload"], t_init, xu, yu, zu)

    xi0 = _nearest_idx(xu, 30.0)
    yi0 = _nearest_idx(yu, -20.0)
    zi0 = _nearest_idx(zu, 520.0)

    fig = plt.figure(figsize=(17.5, 7.5))
    gs = fig.add_gridspec(2, 4, height_ratios=[1, 0.18], hspace=0.30, wspace=0.45)

    ax_xy = fig.add_subplot(gs[0, 0])
    ax_yz = fig.add_subplot(gs[0, 1])
    ax_zx = fig.add_subplot(gs[0, 2])
    ax_info = fig.add_subplot(gs[0, 3])
    ax_info.axis("off")

    cmap_obj = plt.get_cmap("viridis").copy()
    cmap_obj.set_bad(color="black")

    im_xy = ax_xy.imshow(init_vol[:, :, zi0].T, origin="lower", aspect="equal", cmap=cmap_obj)
    im_yz = ax_yz.imshow(init_vol[xi0, :, :].T, origin="lower", aspect="equal", cmap=cmap_obj)
    im_zx = ax_zx.imshow(init_vol[:, yi0, :].T, origin="lower", aspect="equal", cmap=cmap_obj)

    ax_xy.set_xlabel("x (um)")
    ax_xy.set_ylabel("y (um)")
    ax_yz.set_xlabel("y (um)")
    ax_yz.set_ylabel("z (um)")
    ax_zx.set_xlabel("x (um)")
    ax_zx.set_ylabel("z (um)")

    cbar = fig.colorbar(im_xy, ax=[ax_xy, ax_yz, ax_zx], shrink=0.9)
    cbar.set_label(metric_label[init_metric])

    ax_x = fig.add_subplot(gs[1, 0])
    ax_y = fig.add_subplot(gs[1, 1])
    ax_z = fig.add_subplot(gs[1, 2])
    ax_t = fig.add_subplot(gs[1, 3])

    x_sl = Slider(ax_x, "x (um)", float(xu[0]), float(xu[-1]), valinit=float(xu[xi0]), valstep=_safe_step(xu))
    y_sl = Slider(ax_y, "y (um)", float(yu[0]), float(yu[-1]), valinit=float(yu[yi0]), valstep=_safe_step(yu))
    z_sl = Slider(ax_z, "z (um)", float(zu[0]), float(zu[-1]), valinit=float(zu[zi0]), valstep=_safe_step(zu))
    t_sl = Slider(ax_t, "t (ms)", t_min_all, t_max_all, valinit=t_init, valstep=t_step_all)

    info_pos = ax_info.get_position()
    metric_ax = fig.add_axes(
        [
            info_pos.x0 + 0.05 * info_pos.width,
            info_pos.y0 + 0.78 * info_pos.height,
            0.90 * info_pos.width,
            0.19 * info_pos.height,
        ]
    )
    metric_radio = RadioButtons(metric_ax, metric_names, active=metric_names.index(init_metric))
    metric_ax.set_title("Metric", fontsize=10, pad=2)

    dataset_ax = fig.add_axes(
        [
            info_pos.x0 + 0.05 * info_pos.width,
            info_pos.y0 + 0.52 * info_pos.height,
            0.90 * info_pos.width,
            0.23 * info_pos.height,
        ]
    )
    dataset_radio = RadioButtons(dataset_ax, labels, active=0)
    dataset_ax.set_title("Dataset", fontsize=10, pad=2)

    stats_text = ax_info.text(
        0.02,
        0.46,
        "",
        ha="left",
        va="top",
        fontsize=9,
        family="monospace",
    )

    def _set_ticks(ax, arr, axis):
        ticks_idx = np.linspace(0, len(arr) - 1, 5, dtype=int)
        labels_ = [f"{arr[i]:.0f}" for i in ticks_idx]
        if axis == "x":
            ax.set_xticks(ticks_idx)
            ax.set_xticklabels(labels_)
        else:
            ax.set_yticks(ticks_idx)
            ax.set_yticklabels(labels_)

    def _fmt_stats(label: str, metric: str, vol: np.ndarray, xi: int, yi: int, zi: int) -> str:
        finite = vol[np.isfinite(vol)]
        if finite.size == 0:
            return f"[{metric}] no finite data"

        gmin = float(np.min(finite))
        gmax = float(np.max(finite))
        gmean = float(np.mean(finite))
        gstd = float(np.std(finite))

        xy = vol[:, :, zi]
        yz = vol[xi, :, :]
        zx = vol[:, yi, :]

        def mm(a: np.ndarray) -> Tuple[float, float]:
            f = a[np.isfinite(a)]
            if f.size == 0:
                return np.nan, np.nan
            return float(np.min(f)), float(np.max(f))

        mn_xy, mx_xy = mm(xy)
        mn_yz, mx_yz = mm(yz)
        mn_zx, mx_zx = mm(zx)

        ds = datasets[label]
        lines = [
            f"dataset: {label}",
            f"file: {ds['path'].name}",
            f"metric: {metric}",
            f"cell: {ds['cell_id']}",
            f"gain: {ds['gain']}",
        ]
        if metric in ("vm_by_t", "spike_on"):
            lines.append(f"t = {float(t_sl.val):.3f} ms")
        lines.extend([
            "",
            f"global min  : {gmin: .6g}",
            f"global max  : {gmax: .6g}",
            f"global mean : {gmean: .6g}",
            f"global std  : {gstd: .6g}",
            "",
            f"XY min/max @ z={zu[zi]:.0f} : {mn_xy: .6g} / {mx_xy: .6g}",
            f"YZ min/max @ x={xu[xi]:.0f} : {mn_yz: .6g} / {mx_yz: .6g}",
            f"ZX min/max @ y={yu[yi]:.0f} : {mn_zx: .6g} / {mx_zx: .6g}",
        ])
        return "\n".join(lines)

    def update_view(_=None):
        metric = metric_radio.value_selected
        selected_label = dataset_radio.value_selected
        ds = datasets[selected_label]

        t_val = float(t_sl.val)
        t_val = min(max(t_val, ds["t_min"]), ds["t_max"])

        if metric == "vm_by_t":
            vol = _build_vm_by_t_volume(ds["payload"], t_val, xu, yu, zu)
        elif metric == "spike_on":
            vm_vol = _build_vm_by_t_volume(ds["payload"], t_val, xu, yu, zu)
            vol = np.where(np.isfinite(vm_vol), (vm_vol > 0.0).astype(np.float64), np.nan)
        else:
            vol = ds["volumes"][metric]

        xi = _nearest_idx(xu, float(x_sl.val))
        yi = _nearest_idx(yu, float(y_sl.val))
        zi = _nearest_idx(zu, float(z_sl.val))

        slice_xy = vol[:, :, zi]
        slice_yz = vol[xi, :, :]
        slice_zx = vol[:, yi, :]

        vmin, vmax, cmap_name = ds["scale_cache"][metric]

        cmap_sel = plt.get_cmap(cmap_name).copy()
        bad_color = "white" if metric in ("spike_count", "spike_on") else "black"
        cmap_sel.set_bad(color=bad_color)
        for im in (im_xy, im_yz, im_zx):
            im.set_cmap(cmap_sel)
            im.set_clim(vmin, vmax)

        im_xy.set_data(slice_xy.T)
        im_yz.set_data(slice_yz.T)
        im_zx.set_data(slice_zx.T)

        _set_ticks(ax_xy, xu, "x")
        _set_ticks(ax_xy, yu, "y")
        _set_ticks(ax_yz, yu, "x")
        _set_ticks(ax_yz, zu, "y")
        _set_ticks(ax_zx, xu, "x")
        _set_ticks(ax_zx, zu, "y")

        t_suffix = f" t={t_val:.2f}ms" if metric in ("vm_by_t", "spike_on") else ""
        ax_xy.set_title(f"XY ({metric}) z={zu[zi]:.0f} um{t_suffix}")
        ax_yz.set_title(f"YZ ({metric}) x={xu[xi]:.0f} um{t_suffix}")
        ax_zx.set_title(f"ZX ({metric}) y={yu[yi]:.0f} um{t_suffix}")

        cbar.update_normal(im_xy)
        cbar.set_label(metric_label[metric])
        stats_text.set_text(_fmt_stats(selected_label, metric, vol, xi, yi, zi))

        fig.canvas.draw_idle()

    x_sl.on_changed(update_view)
    y_sl.on_changed(update_view)
    z_sl.on_changed(update_view)
    t_sl.on_changed(update_view)
    metric_radio.on_clicked(update_view)
    dataset_radio.on_clicked(update_view)

    update_view()
    plt.show()


def main() -> None:
    parser = argparse.ArgumentParser(
        description=(
            "gradient_allen_v2.py 결과를 3-slice 뷰어로 시각화. "
            "시간 슬라이더로 스파이크 발생 시점 확인 가능."
        )
    )
    parser.add_argument(
        "--input",
        type=str,
        default=None,
        help="Path(s) to v2 summary npy. Comma-separated allowed. Default: load all v2_* in ./data/gradient_allen",
    )
    parser.add_argument(
        "--cell",
        type=str,
        default=None,
        help="Cell ID to load (e.g. 529898751). Filters to v2_*_cell{id}.npy. Default: any.",
    )
    args = parser.parse_args()

    script_dir = Path(__file__).resolve().parent
    if args.input:
        input_paths = [Path(p.strip()) for p in str(args.input).split(",") if p.strip()]
    else:
        input_paths = _find_inputs_v2(script_dir, cell_id=args.cell)

    if not input_paths:
        msg = (
            "v2 input file not found. Run gradient_allen_v2.py first. "
            "Check ./data/gradient_allen/v2_allpoints_gradient_*x_cell*.npy"
        )
        if args.cell:
            msg += f" (cell_id={args.cell})"
        raise SystemExit(msg)

    dataset_items: List[Tuple[str, Path, dict]] = []
    used_labels: Dict[str, int] = {}
    for p in input_paths:
        if not p.exists():
            raise SystemExit(f"Input file does not exist: {p}")
        payload = _load_payload(p)
        base = _dataset_label(p, payload)
        idx = used_labels.get(base, 0)
        used_labels[base] = idx + 1
        label = base if idx == 0 else f"{base} [{idx + 1}]"
        dataset_items.append((label, p, payload))

    print(f"Loaded {len(dataset_items)} dataset(s).")
    for label, p, _ in dataset_items:
        print(f"  - {label}: {p}")
    print("Opening interactive viewer...")
    show_interactive(dataset_items)


if __name__ == "__main__":
    main()
